# 간단회고 - 월간 데이콘 2 천체 유형 분류

## 대회 개요 

슬론 디지털 천체 관측(Sloan Digital Sky Survey: 이하 SDSS) 의 데이터를 이용한

천체의 유형 분류 대회

평가 지표는 LogLoss

대회기간 - 1달

## 접근했던 방법

간단한 EDA만 실시했음. 

Feature의 이해가 전혀 되지 않아서 EDA접근을 어떻게 해야할지 감이 안왔다.

psfMag, petroMag, fiberMag, modelMag 가 각각 u r g i z 로 나뉘니 당황스럽기만했다.

간단히 데이터의 분포를 볼수 있도록 feature 별 box plot 정도만 실시했고, 

outlier로 보이는 요소들이 존재해서 데이터별 -200~ 200으로 제한을 주었다.

이후 EDA는 하지않고 모델링에 집중했으며 Neural Network 사용하여 

각종 모델링을 하였으나 일정 점수 이하로 내려가지 못하는 교착상태에 빠졌다.

단순히 맞는 모델링을 하지 못했다는 생각으로 stacking ensemble 도 하였으나 

결과는 나아지지 않았고, 무엇이 문제인지 찾지 못하는 상태.

데이터 불균형을 발견했었으나, 불균형을 맞추기 위해 했던 방법(over-sampling의 SMOTE)이 

딱히 효과적이거나 하지 않았음. 

불균형이 너무 심하다보니 over-sampling으로 생성되는 데이터가 많아서 그런것이 아닐까 추정

## 돌파구

대회가 final stage 에 진입하기 바로 전날. 상위권 유저분이 진행글을 올렸고

그 글에서 힌트를 얻을 수 있었다.

실패요소는 EDA의 부족이었다.

급한대로 구글링 하여 나온 논문들에 나온 알지도 못하는 Feature들을 보고 

Feature Engineering을 실시, 점수에 돌파구가 생겼고 Final stage에 진입하게 될 수 있었다.

이때부터 model은 트리 기반의 lightGBM으로 교체했다. 

이유는 크게 두가지인데,

첫째로, 모델링이 크게 중요하지 않다고 판단했으며,

둘째로, 계속되는 EDA로인한 검증을 빠르게 해야하는 상황에서 복잡한 NN으로 튜닝 및 학습시간으로 시간을 뺏기면 안되었다.

그렇게 약 일주일의 시간을 벌었고 이후 EDA를 재시작하기 시작했다.

급한 마음에 자세한 EDA를 하지 못하고 Feature들을 마구잡이로 생성해댔고

점수가 올라가기 시작했다.

하루하루가 갈수록 Feature의 이해도가 올라가면서 점수가 조금씩 올라갔으며

정확한 의미는 모르지만, 어느정도 의미가 있는 feature를 생성했다고 생각한다.

마지막에 집중했던것은, Star white dwarf(백색왜성)를 예측하는 확률이 낮아(max가 89~91%였다.) 

여기서 loss가 많이 난다고 판단. 이를 구별해 줄 수 있는 feature 생성에 집중했다.

백색왜성을 특징을 보다가, redshift로 구분할 수 있지 않을까 싶어 관련 글을 보기 시작했고

redshift를 추정할수 있는 feature를 직접 생성할 수 없어(제공되는 feature만 사용가능했고 논문에는 u,r,g,i,z등으로만 표현되었으나 제공받은 feature는 psfMag_u, petroMag_u 등으로 표현되었으며 이는 원 u, r, g, i, z 에서 공식을 통해 파생된 것으로 보인다. feature의 이해도 부족으로 해석하기가 힘들었다.)

간접적으로 redshift를 추정해 줄 수 있을것이라 판단되는 feature들을 생성했다.

하지만 특별하게 더 좋아지는 feature를 생성하지는 못하였다.

그렇게 리더보드는 20위대에 멈추게 되었고 

최종 public 21, private 35위로 종료하게되었다.



## 개선해야 할 점

일단 EDA가 매우 부족했다.  EDA의 중요성에 대해 전혀 생각하지 못하고 있었다.

상위권의 유저중에는 EDA를 통해 특정 조건을 만족하면 QSO를 기계학습 없이도 

판단할 수 있는 방법을 찾아내신 분도 있었다.

Hyper Parameter 를 찾는 방법을 개선해야 할 듯 하다. 

계속 내가 임의로 주었으나, 맞다는 확신이 없어 여러번 시도하며 시간이 많이 낭비된 부분이 있었다.

cross validation과 kfold를 너무 검증이라는 틀 안에서만 생각했다.

즉, 모델을 평가할때만 사용하고 실제 결과를 낼때는 전혀 이용하지 않았다.

fold별 test의 예측 결과를 저장 후 평균을 내서 결과물을 만들어 내는 방법을 생각하지 못했다.

다음에는 이부분에서 개선할 수 있을것이다.

